/*
*
* 2007 Copyright (c) 
* Michael Moser,  <moser.michael@gmail.com>                 
* All rights reserved.
*
* This program is free software; you can redistribute it and/or modify
* it under the terms of the GNU General Public License as published by
* the Free Software Foundation; either version 2 of the License, or
* (at your option) any later version.
*
* This program is distributed in the hope that it will be useful,
* but WITHOUT ANY WARRANTY; without even the implied warranty of
* MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
* GNU General Public License for more details.
*
* You should have received a copy of the GNU General Public License
* along with this program; if not, write to the Free Software
* Foundation, Inc., 59 Temple Place, Suite 330, Boston, MA  02111-1307  USA
*/

comparison of language implementations py poking through their source code
==========================================================================

computer language shootout
--------------------------

http://shootout.alioth.debian.org/gp4sandbox/benchmark.php?test=all&lang=all


1.7	Java 6 -server 	2.08	 

    ^
    |  - very hard to pull of asynchronous stuff with java, not the right mindset, not the right tools, also JIT thing -
    v

13	Lua 	16.59	 

17	Python 	21.01	

21	Perl 	26.72	2  // perl bytecode or regular perl?

23	Ruby YARV 28.92	7  // vm still slower then perl!

52	Ruby 	65.12	2

runtime
-------
    ruby,perl = eval ast 
	(perl has some optional bytecode perl5-8-8/ext/ByteLoader, is it used ?)
	(ruby has a bytecode implementation YARV, is to be merged into next version of ruby, 
	   - but nothing can help ruby on rails since it modifies code dynamically ;-) - )
    
    lua,python = run bytecode
	python - stack based vm
	lua - register based vm


? strings - read-only immutable or variable size buffer ?
    

exceptions
----------
    ruby,python = yes
    lua,perl = no


extending-the-language

misc 
====


   = parsers and everything is driven by some weird definition string;
      maxime seems to be: for every definition, search for the metadefinition;
      everything is passed as pointer to most basic baseclass struct PyObject.

    = include/opcode.h opcode defines
    
    - bytecode interperter is done by ceval.c PyEval_EvalFrameEx 

    = node.h - node : baseclass for ast.

    = include/code.h PyCodeObject - bytecode object.

    = builtin_compile = 

    = python - everything (even integers) is an object.
	every object has pointer to its metaobject definiton (so we see introspection).	
	
	object header:
	--------------

	#define _PyObject_HEAD_EXTRA		\
		struct _object *_ob_next;	\
		struct _object *_ob_prev;

	   /* PyObject_HEAD defines the initial segment of every PyObject. */
	#define PyObject_HEAD			\
		_PyObject_HEAD_EXTRA		\
		Py_ssize_t ob_refcnt;		\
		struct _typeobject *ob_type;

    = object reference counting is for garbage collection
	- they care specially about loops -

	that is every time an object is accessed we have to update reference count for it.
	Lua argues that this costs a lot and thrashes the cache, so they thing that mark and sweep
	garbage collection is actually faster !.
 -=-=-

    = perl ast - defined in op.h/op.c

    = perl from op.c = 
    Perl's compiler is essentially a 3-pass compiler with interleaved phases:
	A bottom-up pass
	A top-down pass
	An execution-order pass
    The bottom-up pass is represented by all the "newOP" routines and
    the ck_ routines.  The bottom-upness is actually driven by yacc.
    So at the point that a ck_ routine fires, we have no idea what the
    context is, either upward in the syntax tree, or either forward or
    backward in the execution order.  (The bottom-up parser builds that
    part of the execution order it knows about, but if you follow the "next"
    links around, you'll find it's actually a closed loop through the
    top level node.
    Whenever the bottom-up parser gets to a node that supplies context to
    its components, it invokes that portion of the top-down pass that applies
    to that part of the subtree (and marks the top node as processed, so
    if a node further up supplies context, it doesn't have to take the
    plunge again).  As a particular subcase of this, as the new node is
    built, it takes all the closed execution loops of its subcomponents
    and links them into a new closed loop for the higher level node.  But
    it's still not the real execution order.
    The actual execution order is not known till we get a grammar reduction
    to a top-level unit like a subroutine or file that will be called by
    "name" rather than via a "next" pointer.  At that point, we can call
    into peep() to do that code's portion of the 3rd pass.  It has to be
    recursive, but it's recursive on basic blocks, not on tree nodes.

    - garbage collection is by reference counting; they don't care about loops
 -=-=-
    lua has no ast, bytecode is generated as we parse the source.
    
    - lua does mark-and-sweep collecting garbage collection, no reference counting for you -

    - values: numbers treated differently from the whole lot

	typedef union {
	  GCObject *gc;
	  void *p;
	  lua_Number n; // double at that.
	  int b;
	} Value;

	#define TValuefields	Value value; int tt /* tt - type tag */

	typedef struct lua_TValue {
	  TValuefields;
	} TValue;
    
    problem: the value is very wide sizeof(int) + sizeof(double) == 2*sizeof(double) - for sake of alignment, 
	      copying it around costs something.

    - instructions: every lua insruction is four bytes wide exactly; leading to limits on number of stack/heap variables.
      but also to shorter cycles
      also very packed instructions. (but closures are slow)
	


